{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification_cnn & transfer learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1i9PimLWa2lifLC5CPjf7rfTMOhz8rYVN",
      "authorship_tag": "ABX9TyOXl4B150sy3cMxQiKoEyJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daakanksha/Fruits-classification-by-transfer-learning/blob/main/image_classification_cnn_%26_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GJUWoHKLvKm",
        "outputId": "bf65b89e-1050-40d6-9011-d0815e5715ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YodDNlxIzDqq"
      },
      "source": [
        "root_path = '/content/drive/MyDrive/verzeo/Artificial intelligence/major'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzqruLsQzhEQ"
      },
      "source": [
        "#import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_CsS5Cy076S"
      },
      "source": [
        "# Loading data and putting them into training and test sets\n",
        "#locations setting for training and test datasets\n",
        "train_data='/content/drive/MyDrive/verzeo/Artificial intelligence/major/fruits-360/Training'\n",
        "test_data='/content/drive/MyDrive/verzeo/Artificial intelligence/major/fruits-360/Test'\n",
        "#creates X_train and Y_train using file_names and folders\n",
        "def get_data(path):\n",
        "    data = load_files(path)\n",
        "    files = np.array(data['filenames'])\n",
        "    targets = np.array(data['target'])\n",
        "    target_labels = np.array(data['target_names'])\n",
        "    return files,targets,target_labels\n",
        "X_train, Y_train, labels = get_data(train_data)\n",
        "X_test, Y_test,_ = get_data(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qooM_GUM08Cn"
      },
      "source": [
        "Y_train = np_utils.to_categorical(Y_train, 120)\n",
        "Y_test = np_utils.to_categorical(Y_test, 120)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yorAj6ElLrTG"
      },
      "source": [
        "# splitting train set into training and validation sets\n",
        "X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=33)\n",
        "Y_train, Y_val = train_test_split(Y_train, test_size=0.2, random_state=33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKQmxualMZR5"
      },
      "source": [
        "#converting images into array to start computation\n",
        "def convert_image_to_array(files):\n",
        "    images_as_array=[]\n",
        "    for file in files:\n",
        "        images_as_array.append(img_to_array(load_img(file)))\n",
        "    return images_as_array\n",
        "X_train = np.array(convert_image_to_array(X_train))\n",
        "X_val = np.array(convert_image_to_array(X_val))\n",
        "X_test = np.array(convert_image_to_array(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yawkq1emMZfO"
      },
      "source": [
        "#nomalizing the pixel values before feeding into a neural network\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_val = X_val.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVLA6koeMZkT",
        "outputId": "2caff881-91b4-4a6e-ecb3-016fc60937b1"
      },
      "source": [
        "#Building model 1 using customized convolutional and pooling layers\n",
        "model = Sequential()\n",
        "#input_shape is 100*100 since thats the dimension of each of the fruit images\n",
        "model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "# specifying parameters for fully connected layer\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(120,activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 100, 16)      208       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 100, 100, 16)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 50, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 50, 50, 32)        2080      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 25, 25, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 128)       32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 150)               691350    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               18120     \n",
            "=================================================================\n",
            "Total params: 752,910\n",
            "Trainable params: 752,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhB9N1rkMZm6"
      },
      "source": [
        "#importing ootimizers\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "optimizer = Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3yHWyLfMZr-",
        "outputId": "81a6c48b-e84a-4d99-da70-1b586ff3ab88"
      },
      "source": [
        "# creating a file to save the trained CNN model \n",
        "checkpointer = ModelCheckpoint(filepath = 'cnn_from_scratch_fruits.hdf5', verbose = 1, save_best_only = True)\n",
        "# fitting model using above defined layers \n",
        "CNN_model = model.fit(X_train,Y_train,\n",
        "        batch_size = 128,\n",
        "        epochs=20,\n",
        "        validation_data=(X_val, Y_val),\n",
        "        callbacks = [checkpointer],\n",
        "        verbose=2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "15/15 - 48s - loss: 2.8441 - accuracy: 0.2219 - val_loss: 1.5020 - val_accuracy: 0.4586\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.50202, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 2/20\n",
            "15/15 - 14s - loss: 1.4806 - accuracy: 0.4437 - val_loss: 0.8006 - val_accuracy: 0.8726\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.50202 to 0.80057, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 3/20\n",
            "15/15 - 14s - loss: 0.7472 - accuracy: 0.7022 - val_loss: 0.3031 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.80057 to 0.30309, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 4/20\n",
            "15/15 - 14s - loss: 0.2684 - accuracy: 0.9437 - val_loss: 0.0605 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.30309 to 0.06054, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 5/20\n",
            "15/15 - 15s - loss: 0.1054 - accuracy: 0.9788 - val_loss: 0.0300 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.06054 to 0.02999, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 6/20\n",
            "15/15 - 16s - loss: 0.0680 - accuracy: 0.9830 - val_loss: 0.0205 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.02999 to 0.02053, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 7/20\n",
            "15/15 - 16s - loss: 0.0514 - accuracy: 0.9867 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.02053\n",
            "Epoch 8/20\n",
            "15/15 - 14s - loss: 0.0400 - accuracy: 0.9851 - val_loss: 0.0088 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.02053 to 0.00876, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 9/20\n",
            "15/15 - 14s - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00876 to 0.00333, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 10/20\n",
            "15/15 - 14s - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00333 to 0.00195, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 11/20\n",
            "15/15 - 14s - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00195 to 0.00129, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 12/20\n",
            "15/15 - 14s - loss: 0.0097 - accuracy: 0.9984 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00129\n",
            "Epoch 13/20\n",
            "15/15 - 14s - loss: 0.0066 - accuracy: 0.9989 - val_loss: 5.6316e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00129 to 0.00056, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 14/20\n",
            "15/15 - 14s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6341e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00056 to 0.00026, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 15/20\n",
            "15/15 - 14s - loss: 0.0035 - accuracy: 0.9995 - val_loss: 1.5243e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00026 to 0.00015, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 16/20\n",
            "15/15 - 14s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.9003e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00015\n",
            "Epoch 17/20\n",
            "15/15 - 14s - loss: 0.0057 - accuracy: 0.9995 - val_loss: 6.4567e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00015\n",
            "Epoch 18/20\n",
            "15/15 - 14s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3079e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00015 to 0.00013, saving model to cnn_from_scratch_fruits.hdf5\n",
            "Epoch 19/20\n",
            "15/15 - 14s - loss: 0.0035 - accuracy: 0.9989 - val_loss: 1.8088e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00013\n",
            "Epoch 20/20\n",
            "15/15 - 14s - loss: 0.0056 - accuracy: 0.9979 - val_loss: 2.0204e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjJF5XBnMZuo"
      },
      "source": [
        "#loading saved weights to use further\n",
        "model.load_weights('cnn_from_scratch_fruits.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nnpm-an3Y0K",
        "outputId": "2eb565b8-8aec-48ca-93ca-444f738e27bf"
      },
      "source": [
        "#importing vgg16\n",
        "#Part 2 using transfer learning\n",
        "#importing vgg16 architecture which is trained on Imagenet\n",
        "from keras.applications.vgg16 import VGG16\n",
        "vgg_model = VGG16(input_shape=[100,100,3], weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSrguww53Y3S",
        "outputId": "bf55af57-dcf9-44a2-e4bc-9c3890595392"
      },
      "source": [
        "for layer in vgg_model.layers:\n",
        "   layer.trainable = False\n",
        "vgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d4MGMlv3Y6p",
        "outputId": "a0dee224-5add-4daf-c711-b7b3323b128c"
      },
      "source": [
        "transfer_learning_model = Sequential()\n",
        "transfer_learning_model.add(vgg_model)\n",
        "transfer_learning_model.add(Conv2D(1024, kernel_size=3, padding='same'))\n",
        "transfer_learning_model.add(Activation('relu'))\n",
        "transfer_learning_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "transfer_learning_model.add(Dropout(0.3))\n",
        "transfer_learning_model.add(Flatten())\n",
        "transfer_learning_model.add(Dense(150))\n",
        "transfer_learning_model.add(Activation('relu'))\n",
        "transfer_learning_model.add(Dropout(0.4))\n",
        "transfer_learning_model.add(Dense(120,activation = 'softmax'))\n",
        "transfer_learning_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 3, 3, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3, 3, 1024)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 150)               153750    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 120)               18120     \n",
            "=================================================================\n",
            "Total params: 19,606,174\n",
            "Trainable params: 4,891,486\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLNXdJwA3Y8j"
      },
      "source": [
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "optimizer = Adam()\n",
        "transfer_learning_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBz_5K8z3Y-U",
        "outputId": "31952374-5a0c-4a24-9ae6-f79351f82b87"
      },
      "source": [
        "#fitting the new model\n",
        "checkpointer = ModelCheckpoint(filepath = 'transfer_learning.hdf5', verbose = 1, save_best_only = True)\n",
        "# running \n",
        "transfer_learning_cnn = transfer_learning_model.fit(X_train,Y_train,\n",
        "        batch_size = 128,\n",
        "        epochs=20,\n",
        "        validation_data=(X_val, Y_val),\n",
        "        callbacks = [checkpointer],\n",
        "        verbose=2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "15/15 - 247s - loss: 1.7372 - accuracy: 0.5069 - val_loss: 0.3457 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.34566, saving model to transfer_learning.hdf5\n",
            "Epoch 2/20\n",
            "15/15 - 241s - loss: 0.3385 - accuracy: 0.8944 - val_loss: 0.0474 - val_accuracy: 0.9915\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.34566 to 0.04737, saving model to transfer_learning.hdf5\n",
            "Epoch 3/20\n",
            "15/15 - 238s - loss: 0.1023 - accuracy: 0.9724 - val_loss: 0.0215 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.04737 to 0.02151, saving model to transfer_learning.hdf5\n",
            "Epoch 4/20\n",
            "15/15 - 238s - loss: 0.0521 - accuracy: 0.9873 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.02151 to 0.00544, saving model to transfer_learning.hdf5\n",
            "Epoch 5/20\n",
            "15/15 - 242s - loss: 0.0179 - accuracy: 0.9973 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00544 to 0.00164, saving model to transfer_learning.hdf5\n",
            "Epoch 6/20\n",
            "15/15 - 241s - loss: 0.0112 - accuracy: 0.9989 - val_loss: 9.5202e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00164 to 0.00095, saving model to transfer_learning.hdf5\n",
            "Epoch 7/20\n",
            "15/15 - 238s - loss: 0.0073 - accuracy: 0.9995 - val_loss: 6.0502e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00095 to 0.00061, saving model to transfer_learning.hdf5\n",
            "Epoch 8/20\n",
            "15/15 - 238s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.6536e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00061 to 0.00037, saving model to transfer_learning.hdf5\n",
            "Epoch 9/20\n",
            "15/15 - 239s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.5665e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00037 to 0.00036, saving model to transfer_learning.hdf5\n",
            "Epoch 10/20\n",
            "15/15 - 237s - loss: 0.0050 - accuracy: 0.9995 - val_loss: 2.4363e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00036 to 0.00024, saving model to transfer_learning.hdf5\n",
            "Epoch 11/20\n",
            "15/15 - 235s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.5379e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00024\n",
            "Epoch 12/20\n",
            "15/15 - 235s - loss: 0.0037 - accuracy: 0.9995 - val_loss: 1.7132e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00024 to 0.00017, saving model to transfer_learning.hdf5\n",
            "Epoch 13/20\n",
            "15/15 - 236s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0540e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00017 to 0.00011, saving model to transfer_learning.hdf5\n",
            "Epoch 14/20\n",
            "15/15 - 238s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 8.1785e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00011 to 0.00008, saving model to transfer_learning.hdf5\n",
            "Epoch 15/20\n",
            "15/15 - 236s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3306e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00008\n",
            "Epoch 16/20\n",
            "15/15 - 236s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 8.5727e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00008\n",
            "Epoch 17/20\n",
            "15/15 - 235s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.2457e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00008 to 0.00005, saving model to transfer_learning.hdf5\n",
            "Epoch 18/20\n",
            "15/15 - 235s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.6602e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00005\n",
            "Epoch 19/20\n",
            "15/15 - 236s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.5091e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00005\n",
            "Epoch 20/20\n",
            "15/15 - 238s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.4478e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00005 to 0.00004, saving model to transfer_learning.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiQjeSOs3ZBN"
      },
      "source": [
        "transfer_learning_model.load_weights('transfer_learning.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1a77hT8fwui"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}